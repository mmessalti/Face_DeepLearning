{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsampler import ImbalancedDatasetSampler\n",
    "# In the folder \"test_images\" you can/should combine \"google_faces\" and \"yale_faces\" and rename it to \"1\"  (faces) and the other one \"google_images02_36x36\" to \"0\" (non-faces)\n",
    "train_dir = './train_images'\n",
    "test_dir = './test_images'\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.Grayscale(), \n",
    "     transforms.ToTensor(), \n",
    "     transforms.Normalize(mean=(0,),std=(1,))])\n",
    "\n",
    "train_data = torchvision.datasets.ImageFolder(train_dir, transform=transform)\n",
    "test_data = torchvision.datasets.ImageFolder(test_dir, transform=transform)\n",
    "\n",
    "valid_size = 0.2\n",
    "batch_size = 32\n",
    "\n",
    "num_train = len(train_data)\n",
    "indices_train = list(range(num_train))\n",
    "np.random.shuffle(indices_train)\n",
    "split_tv = int(np.floor(valid_size * num_train))\n",
    "train_new_idx, valid_idx = indices_train[split_tv:],indices_train[:split_tv]\n",
    "\n",
    "# train_sampler = SubsetRandomSampler(train_new_idx)\n",
    "# valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "\n",
    "train_sampler = ImbalancedDatasetSampler(train_data, train_new_idx)\n",
    "valid_sampler = ImbalancedDatasetSampler(train_data, valid_idx)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, sampler=train_sampler, num_workers=1)\n",
    "valid_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, sampler=valid_sampler, num_workers=1)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, shuffle=True, num_workers=1)\n",
    "classes = ('noface','face')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 200, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv2): Conv2d(200, 500, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=40500, out_features=300, bias=True)\n",
      "  (fc2): Linear(in_features=300, out_features=100, bias=True)\n",
      "  (fc3): Linear(in_features=100, out_features=2, bias=True)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (relu): ReLU()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# for epoch in range(1, n_epochs+1):\n",
    "# for data, target in train_loader:*\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Linear, ReLU, CrossEntropyLoss, Sequential, Conv2d, MaxPool2d, Module, Softmax, BatchNorm2d, Dropout\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=200, kernel_size=3, padding=1)  # notice the padding\n",
    "        self.conv2 = nn.Conv2d(in_channels=200, out_channels=500, kernel_size=3, padding=1) # again...        \n",
    "        self.pool = nn.MaxPool2d(2,2)\n",
    "        self.fc1 = nn.Linear(500*9*9, 300) # it is 64....\n",
    "        self.fc2 = nn.Linear(300, 100)\n",
    "        self.fc3 = nn.Linear(100, 2)\n",
    "        self.dropout = torch.nn.Dropout(p=0.5)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "\n",
    "    # Defining the forward pass    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = F.max_pool2d(x, (2,2))\n",
    "        x = self.conv2(x) \n",
    "        x = self.relu(x)\n",
    "        x = F.max_pool2d(x, 2) \n",
    "        #print(x.shape)\n",
    "        x = x.reshape(x.size(0), -1) \n",
    "        \n",
    "        x = self.fc1(x) \n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x) \n",
    "        x = self.dropout(x)\n",
    "        prediction = self.fc3(x) \n",
    "        return prediction      \n",
    "\n",
    "device = \"cpu\"\n",
    "if (torch.cuda.is_available()):\n",
    "    device = \"cuda\"\n",
    "\n",
    "net = Net()\n",
    "print(net)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # for epoch in range(1, n_epochs+1):\n",
    "# # for data, target in train_loader:*\n",
    "\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "\n",
    "\n",
    "# class Net(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(Net, self).__init__()\n",
    "#         # 1 input image channel, 6 output channels, 3x3 square convolution\n",
    "#         # kernel\n",
    "#         self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=3,stride=1, padding=1)\n",
    "#         self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "#         self.pool = nn.MaxPool2d(kernel_size=2)\n",
    "#         self.drop = nn.Dropout2d(p=0.2) #drop layer deletes 20% of features to help prevent overfitting\n",
    "        \n",
    "#         self.fc = nn.Linear(16 * 7 * 7, 2)\n",
    "        \n",
    "# #         # an affine operation: y = Wx + b\n",
    "# #         self.fc = nn.Linear(16* 7 * 7, 120)  # 6*6 from image dimension\n",
    "# #         self.fc2 = nn.Linear(120, 84)\n",
    "# #         self.fc3 = nn.Linear(in_features = 84, out_features = 2)\n",
    "         \n",
    "#     def forward(self, x):\n",
    "#         x = F.relu(self.pool(self.conv1(x)))\n",
    "#         x = F.relu(self.pool(self.conv2(x)))\n",
    "#         x = F.dropout(self.drop(x), training = self.training)\n",
    "#         x = x.view(-1, self.num_flat_features(x))\n",
    "#         x = self.fc(x)\n",
    "        \n",
    "#         return torch.log_softmax(x, dim=1)\n",
    "# #         # Max pooling over a (2, 2) window\n",
    "# #         x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "# #         # If the size is a square you can only specify a single number\n",
    "# #         x = F.max_pool2d(F.relu(self.conv2(x)), (2, 2))\n",
    "# #         x = F.max_pool2d(F.relu(self.conv3(x)), 2)\n",
    "\n",
    "# #         x = x.view(-1, self.num_flat_features(x))\n",
    "# #         x = F.relu(self.fc1(x))\n",
    "# #         x = F.relu(self.fc2(x))\n",
    "# #         x = self.fc3(x)\n",
    "# #         return x\n",
    "\n",
    "#     def outputSize(in_size, kernel_size, stride, padding):\n",
    "#         output = int((in_size - kernel_size + 2*(padding)) / stride) + 1\n",
    "#         return(output)\n",
    "\n",
    "#     def num_flat_features(self, x):\n",
    "#         size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "#         num_features = 1\n",
    "#         for s in size:\n",
    "#             num_features *= s\n",
    "#         return num_features\n",
    "\n",
    "# device = \"cpu\"\n",
    "# if (torch.cuda.is_available()):\n",
    "#     device = \"cuda\"\n",
    "\n",
    "# net = Net()\n",
    "# print(net)\n",
    "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2897\n",
      "[1,  2000] loss: 0.693\n",
      "[2,  2000] loss: 0.693\n",
      "[3,  2000] loss: 0.693\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "net.to(device)\n",
    "\n",
    "n_epoch = int(num_train/batch_size)\n",
    "print(n_epoch)\n",
    "for epoch in range(3):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')\n",
    "\n",
    "net = Net()\n",
    "net.to(device)\n",
    "\n",
    "PATH = './cifar_net.pth'\n",
    "torch.save(net.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net()\n",
    "\n",
    "net.load_state_dict(torch.load(PATH))\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
